# Housing Prices Advanced Regression Model

## ğŸ“Œ Project Overview
This project aims to predict housing prices using advanced regression techniques. The dataset used is the **Ames Housing dataset**, which contains 80 various features such as lot size, number of rooms, location, and house conditions.

## ğŸ” Problem Statement
The goal of this project is to develop a **Machine Learning model** that accurately predicts house prices based on various features. This is a **regression problem** where we minimize the error between predicted and actual prices.

## ğŸ“Š Dataset Description
- **Dataset**: Ames Housing Dataset
- **Target Variable**: `SalePrice` (House Price)
- **Features**: Various structural, locational, and neighborhood features

## ğŸš€ Project Workflow
1. **Exploratory Data Analysis (EDA)** ğŸ§
   - Understanding data distributions and missing values
   - Feature correlations and outliers detection

2. **Data Preprocessing** âš™ï¸
   - Handling missing values
   - Encoding categorical variables (Target Encoding)
   - Feature engineering and scaling (Log Transformation on Right-Skewed Response Data)
   - Remove highly uncorrelated features  (< 0.3 correlation with SalePrice was removed )

4. **Model Selection & Training** ğŸ¤–
   - Implementing regression models (XGBoost)
   - Hyperparameter tuning using **Optuna**
   - Cross-validation to ensure robustness

5. **Evaluation & Results** ğŸ“ˆ
   - RMSE, MAE, RÂ² scores on validation data
   - Model comparison and selection

## ğŸ›  Technologies Used
- **Python** ğŸ
- **Jupyter Notebook** ğŸ““
- **Scikit-Learn** ğŸ¤–
- **XGBoost** âš¡
- **Pandas & NumPy** ğŸ“Š
- **Matplotlib & Seaborn** ğŸ“‰

## ğŸ”¥ How to Run the Project
### **1ï¸âƒ£ Install Train and Test  Data
Change the file path when importing data 

### **2ï¸âƒ£ Run the Jupyter Notebook**
```bash
jupyter notebook housing-prices-advanced-regression.ipynb
```

### **3ï¸âƒ£ Train the Model**
Run all cells to train and evaluate the model.


## ğŸ“Œ Results & Conclusion
- The best-performing model achieved an **RMSE of 0.13510*.
![Model Performance](Kaggle_Submission_Score.png)
- Feature engineering and hyperparameter tuning significantly improved accuracy. (hypertuning improved accuracy by 7percent)
- Future improvements could include **feature selection, ensemble methods, and deeper hyperparameter optimization**.

## âœ‰ï¸ Contact
For any questions, feel free to reach out at @bigmanting on telegram  or email roysougata19705@gmail.com

